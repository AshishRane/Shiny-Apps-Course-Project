ppois(2,2)
ppois(4,2)
ppois(6,2)
set.seed(20)
x<-rnorm(100)
e<-rnorm(100,0,2)
y<-0.5+2*x+e
plot(x,y)
x<-rbinom(100,1,0.5)
e<-rnorm(100,0,2)
y<-0.5+2*x+e
plot(x,y)
set.seed(1)
x<-rnorm(100)
log.mu<-0.5+0.3*x
y<-rpois(100,exp(log.mu))
summary(y)
plot(x,y)
set.seed(1)
sample(1:10,4)
sample(1:10,4)
sample(letters,5)
sample(1:10)
sample(1:10, replace=TRUE)
lm(y~x)
$by.total
by.total
sample.interval
set.seed(1)
rpois(5, 2)
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
y
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
by.total
mean(abs(rnorm(100)))
rnorm(10)
pdf("xh.pdf") #set graphical output file
hist(rnorn(100)) #generate 100 N(0,1) variates and plot their histogram
dev.off() # close the graphical output file
pdf("xh.pdf") #set graphical output file
hist(rnorm(100)) #generate 100 N(0,1) variates and plot their histogram
dev.off() # close the graphical output file
R CMD BATCH z.R
R CMD BATCH z.R
R CMD BATCH z.R
data()
str(Nile)
mean(Nile)
sd(nile)
sd(Nile)
hist(Nile)
x <- list(u=2, v="abc")
x
x$u
x$v
hn <- hist(Nile)
hn
print(hn)
str(hn)
d <- data.frame(list(kids=c("Jack","Jill"), ages=c(10,12)))
d
hist(d)
example(lm)
example(list)
example(seq)
example(persp)
help.search("multivariate normal")
typeof(d)
d <- data.frame(list(kids=c("Jack","Jill"), ages=c(10,12)))
typeof(d)
2%%2
2%%1
2%%3
?%%
?"%%"
1%%5
2%%4
4"%%"-1
4%%-1
example("%%")
y <- c(2.3,8,5,4,3,5.4)
y[c(1,3)]
y[c(3,5)]
y[c(3,5,6)]
z <- y[c(1:length(y)-1)]
z
z <- y[c(1:length(y)-2)]
z <- y[c(1:length(y)-1)]
z
y <- matrix(c(1,2,3,4,5,6), nrow=3, ncol=2)
y
y <- matrix(c(1,2,3,4,5,6))
y
y <- matrix(c(1,2,3,4,5,6), nrow=3)
y
y <- matrix(c(1,2,3,4,5), nrow=3)
y
y[,2]
y[1,]
y[,1]
classOf(y)
class(y)
y <- matrix(c(1,2,3,4), nrow=2, ncol=2)
y
y%%y
y%*%y
y*y
y
1*1+1*2+2*1+2*2
example("%*%")
?%*%
?"%*%"
y
y <- matrix(c(1,2,3,4), nrow=2, ncol=2)
y%*%y
y
a <- rep(y,y)
a
y%*%y
1*1+3*2
1*3+3*4
2*1+4*2
2*3+4*4
library(pixmap)
install.packages("pixmap")
library(pixmap)
mtrush1 <- read.pnm("mtrush1.pgm")
class(y)
attributes(y)
j <- list(name="Joe", salary=55000, union=T)
j
j$sal
j$n
j$u
j[[salary]]
j[["salary"]]
j[[2]]
sapply(list(1:5),mean)
sapply(list(1:5,6:10),mean)
lapply(list(1:5,6:10),mean)
sim <- function(nreps){
commdata <- list()
commdata$countabsamecomm <- 0
for (rep in 1:nreps) {
commdata$whosleft <- 1:20
commdata$numabchosen <- 0
commdata <- chosecomm(commdata,5)
if(commdata$numabchosen > 0) next
commdata <- choosecom(commdata,4)
if(commdata$numabchosen > 0) next
commdata <- choosecom(commdata, 3)
}
print(commdata$countabsamecomm/nreps)
}
formals(g)
g function(x){
return(x+1)
}
abline
page(abline)
sum
library(sql)
library(sqldf)
sqldf("select pwgtp1 from acs")
acs <- dbReadTable("getdata-data-ss06pid.csv")
acs <- dbReadTable("getdata-data-ss06pid.csv")
qunif(0.75)
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
mean(p*x)
mean <- sum(temp[1, ]*temp[2, ])
mean
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
z <- x*w
mean(z)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
install.packages("UsingR")
library(UsingR);data(galton)
par(mfrow=c(1,2))
hist(galton$child,col="blue",breaks=100)
hist(galton$parent,col="blue",breaks=100)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
summary(fit)
e <- resid(fit)
sqe <- e*e
res.var <- sum(sqe) / (length(e) - 2)
sqrt(res.var)
data(mtcars)
attach(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit)
exp <- fit$coefficients[1] + mean(wt) * fit$coefficients[2]
exp - 2 * 0.5591
?mtcars
summary(fit)
fit[[1]][1] + 3 * fit[[1]][2]
summary(fit)
2 * (fit$coefficients[2] - 2 * 0.5591)
attributes(fit)
w.c <- fit$residuals ^ 2
fit.c <- lm(mpg ~ 1, mtcars)
fit.c.res <- fit.c$residuals ^ 2
sum(fit.c.res)
sum(w.c) /sum(fit.c.res)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
summary(fit)
e <- resid(fit)
sqe <- e*e
res.var <- sum(sqe) / (length(e) - 2)
sqrt(res.var)
data(mtcars)
attach(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit)
exp <- fit$coefficients[1] + mean(wt) * fit$coefficients[2]
exp - 2 * 0.5591
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
install.packages("caret")
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength,
p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
featurePlot(x = training[,c('Cement',
'BlastFurnaceSlag',
'FlyAsh',
'Water',
'Superplasticizer',
'CoarseAggregate',
'FineAggregate', 'Age')],
y = training$CompressiveStrength )
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength,
p = 3/4)[[1]]
inTrain = createDataPartition(mixtures$CompressiveStrength,
p = 3/4)[[1]]
inTrain = createDataPartition(mixtures$CompressiveStrength,
p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, data=training)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
set.seed(3433)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis,
p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh = 0.8, outcome = training$diagnosis)
preProc
preProc <- preProcess(ss, method='pca', thresh = 0.9, outcome = training$diagnosis)
preProc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- testing[,grep('^IL', x = names(testing) )]
model1 <- train(ss, testing$diagnosis, method='glm')
model2 <- preProcess(ss, method='pca', thresh = 0.8, outcome = testing$diagnosis)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- testing[,grep('^IL', x = names(testing) )]
model1 <- train(ss, testing$diagnosis, method='glm')
library(e1071)
install.packages("e1071")
library(e1071)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- testing[,grep('^IL', x = names(testing) )]
model1 <- train(ss, testing$diagnosis, method='glm')
model2 <- preProcess(ss, method='pca', thresh = 0.8, outcome = testing$diagnosis)
model1
model2
model2
library(e1071)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- testing[,grep('^IL', x = names(testing) )]
model1 <- train(ss, testing$diagnosis, method='glm')
model2 <- preProcess(ss, method='pca', thresh = 0.8, outcome = testing$diagnosis)
model1
model2
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
compare <- anova(fit1, fit2)
compare$Pr
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
hatvalues(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
dfbetas(fit)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
training = segmentationOriginal[segmentationOriginal$Case == "Train",]
testing = segmentationOriginal[segmentationOriginal$Case == "Test",]
set.seed(125)
M <- train(Class ~ ., data=training, method="rpart")
M
M$finalModel
plot(M$finalModel)
text(M$finalModel)
plot(M$finalModel)
text(M$finalModel)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
library(rattle)
install.packages(rattle)
install.packages("rattle")
library(rattle)
set.seed(125)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ ., data = train, method = "rpart")
modFit$finalModel
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
predict(modFit, newdata = train)
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
fit <- train(Area~.,data=olive,method="rpart")
pred <- predict(fit,newdata)
fancyRpartPlot(fit$finalModel)
library(rpart)
fit <- train(Area~.,data=olive,method="rpart")
pred <- predict(fit,newdata)
fancyRpartPlot(fit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(fit$finalModel)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
fit <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd,predict(fit,trainSA))
missClass(testSA$chd,predict(fit,testSA))
library(rattle)
summary(segmentationOriginal$Case)
inTrain <- grep("Train",segmentationOriginal$Case)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
fit <- train(Class~.,data=training,method="rpart")
fancyRpartPlot(fit$finalModel)
predData <- training[1:3,]
which(colnames(training)=="TotalIntenCh2")
which(colnames(training)=="FiberWidthCh1")
which(colnames(training)=="PerimStatusCh1")
#TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2
#FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2
predData[1,c(103,50,85)]=c(23000,10,2)
predData[2,c(103,50,85)]=c(50000,10,100)
predData[3,c(103,50,85)]=c(57000,8,100)
predict(fit,predData)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(randomForest)
install.packages("randomForest")
library(randomForest)
library(caret)
owel.train$y <- factor(vowel.train$y)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
fit1 <- train(y ~ ., data = vowel.train, method = "rf", trControl = trainControl(number = 4))
fit2 <- train(y ~ ., data = vowel.train, method = "gbm")
predict1 <- predict(fit1, newdata = vowel.test)
predict2 <- predict(fit2, newdata = vowel.test)
predict1
DF_combined <- data.frame(predict1, predict2, y = vowel.test$y)
fit_combined <- train(y ~ ., data = DF_combined, method = "gam")
predict3 <- predict(fit_combined, newdata = vowel.test)
c1 <- confusionMatrix(predict1, vowel.test$y)
c2 <- confusionMatrix(predict2, vowel.test$y)
c3 <- confusionMatrix(predict3, DF_combined$y)
c1
predict2
swirl()
library(swirl)
swirl()
install_from_swirl("Regression Models")
swirl()
plot(child ~ parent, galton)
plot(jitter(child,4)
exit()
swril()
swirl()
3
3
exi()
exit()
0
0
quit()
df.car_specs <- read.csv(url("http://www.sharpsightlabs.com/wp-content/uploads/2015/01/auto-snout_car-specifications_COMBINED.txt"))
library(ggplot2)
ggplot(df.car_specs, aes(horsepower_bhp,top_speed_mph)) + geom_point()
ggplot(df.car_specs, aes(horsepower_bhp,top_speed_mph)) + geom_line()
ggplot(df.car_specs, aes(horsepower_bhp,top_speed_mph)) + geom_point()
install.packages("shiny")
library(ggplot2)
library(shiny)
shiny::runApp('Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project')
shiny::runApp('Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project')
shiny::runApp('Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project')
shiny::runApp('Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project')
shiny::runApp('Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project')
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='ashishrane', token='4E16EE6BF0DAE2DF400BD58915DAA1BD', secret='NeEEzzqgTjShe9tnnCV22kJ4BnulHwnhSk35wf0r')
getwd()
setwd("~/Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project")
library(shinyapps)
shinyapps::deployApp('~/Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project')
deployApp()
library(shinyapps)
deployApp()
library(shiny)
runApp()
library(shinyapps)
deployApp()
deployApp(appName="MyApp")
runApp()
getwd()
setwd("~/Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project/MyApp")
runApp()
runApp(MyApp)
runApp(appName="MyApp")
shiny::runApp('~/Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project')
shiny::runApp('~/Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project')
setwd("~/Desktop/Delete")
shiny::runApp()
shiny::runApp()
shiny::runApp('~/Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project')
shiny::runApp('~/Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project')
setwd("~/Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project/MyApp")
deployApp(appName="MyApp")
shiny::runApp('~/Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project')
library(shinyApps)
library(shinyapps)
runApp()
shiny::runApp('~/Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project')
shiny::runApp('~/Documents/MyDocs/Big Data/Data Science/Coursera/Data Science/Developing Data Products/Course Project')
deployApp()
